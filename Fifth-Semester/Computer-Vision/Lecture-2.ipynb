{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567371b1",
   "metadata": {},
   "source": [
    "### Linear Filtering\n",
    "\n",
    "**Basic Operations like**: Rotation, Scaling, rgb2gray, Defocus, Denoising, Edge Detection\n",
    "\n",
    "Liner transformations $$f[n,m] = \\sum_{k=0}^{N-1} \\sum_{l=0}^{M-1} h[n,m,k,l] g[k,l] $$ or equivalent matrix multiplications $H: f = H g$ output pixel at `(n,m)` depends on **all input pixels `(k,l)`** with weights given by `h`\n",
    "\n",
    "So here the filter $h[n,m,k,l]$ is depandent on input and output coordinates **can behave differently at every pixel**\n",
    "\n",
    "The **solution** is **translation invariance**: We want the same filter everywhere in the image.\n",
    "\n",
    "### Linear Translation Invariant (LTI) Systems\n",
    "\n",
    "**Cross-correlation** and **convolution** are both linear and **translation invariant** operations when applied with a fixed kernel. They differ only by a kernel flip.\n",
    "\n",
    "#### Cross-Correlation\n",
    "\n",
    "$$ f[n,m] = g o h = \\sum_{k=-N}^{N} \\sum_{l=-N}^{N} g[n+k,m+l] h[k,l] $$\n",
    "\n",
    "**h** kernel is $(-N,N) \\times (-N,N)$ sized.\n",
    "\n",
    "Example usage: **Zero padding**\n",
    "\n",
    "#### Convolution\n",
    "\n",
    "The **kernel is flipped** in comparison to cross-correlation.\n",
    "\n",
    "**Properties of Convolution:**\n",
    "- Commutative (no distinction between filter and image $hog = goh$)\n",
    "- Associative (order of 2 convolutions doesnt matter $f o (g o h) = (f o g) o h$)\n",
    "- Distributive over addition $f o (g + h) = f o g + f o h$\n",
    "\n",
    "$$ f[n,m] = g o h = \\sum_{k=-N}^{N} \\sum_{l=-N}^{N} g[n - k,m - l] h[k,l] $$\n",
    "\n",
    "Index goes backwards in g and nicer in mathematics.\n",
    "\n",
    "If **filter is symmetric**, convolution and cross-correlation are the **same**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306af01",
   "metadata": {},
   "source": [
    "### More Neighborhood Filters\n",
    "\n",
    "Many real-world image problems =  unknown convolution kernel + clean image\n",
    "\n",
    "Blurring removes high-frequency details\n",
    "\n",
    "- **Rectangular filters (box filters)**\n",
    "    - **Horizontal rectangular filter**: Kernel is wide and short → horizontal motion blur\n",
    "    - **Vertical rectangular filter**: Kernel is tall and thin → vertical motion blur\n",
    "\n",
    "Box filters make image ugly as problems are:\n",
    "- All neighbors get equal weight\n",
    "- Sharp edges are destroyed\n",
    "- Looks unnatural\n",
    "\n",
    "**Solution** is a **fuzzy blob** kernel (In mathematics: **Gaussian kernel**)\n",
    "\n",
    "#### Gaussian Kernel\n",
    "$$G(x,y) = \\frac{1}{2\\pi\\sigma^2}\n",
    "\\exp\\left(-\\frac{x^2 + y^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "$σ$ = how strong the blur is\n",
    "\n",
    "- The center pixel has the highest weight\n",
    "- Neighbor pixels have smaller weights\n",
    "- Weights decrease smoothly with distance\n",
    "- The shape is round and smooth\n",
    "\n",
    "Gaussian filtering produces smoother and more natural blur than box filtering because it weights pixels based on distance.\n",
    "\n",
    "The convolution of two Gaussian filters results in another Gaussian filter with increased standard deviation.\n",
    "\n",
    "$σ$ o $σ$ = $σ\\sqrt{2}$\n",
    "\n",
    "Blurring many times with small σ ≈ blurring once with a larger σ\n",
    "\n",
    "##### Gaussian filters are separable\n",
    "\n",
    "A 2D Gaussian filter can be separated into two 1D filters (x and y)\n",
    "\n",
    "Applying two 1D filters $O(2N)$ is more efficient than applying one 2D filter $O(N^2)$\n",
    "\n",
    "---\n",
    "\n",
    "#### Derivative Filters\n",
    "\n",
    "Measure rate of change in an image\n",
    "\n",
    "- If two neighboring pixels are similar → small value\n",
    "- If very different → large value → edge\n",
    "\n",
    "##### Problem with simple derivative filters\n",
    "- They react to everything, Noise, Texture, Tiny changes\n",
    "- So the derivative image looks: Very noisy, Hard to tell where the real edge is\n",
    "\n",
    "##### Solution: Smooth first\n",
    "- Step 1: Smooth first using **Gaussian filter**\n",
    "- Step 2: Then apply derivative filter: Removes noise, keeps important edges\n",
    "- Easier way: **Derivative of Gaussian filter (DoG)**\n",
    "\n",
    "Combine steps 1 and 2 into one filter by convolving Gaussian + derivative filter:\n",
    "$$ \\frac{d}{dx}(f*h) = f * \\frac{d}{dx}h $$\n",
    "\n",
    "Can happen in :\n",
    "- x-direction → detects vertical edges\n",
    "- y-direction → detects horizontal edges\n",
    "- $σ$ controls smoothing and edge scale\n",
    "    - Small $σ$ → Sensitive to noise\n",
    "    - Large $σ$ → Ignores small details and detects stronger edges\n",
    "\n",
    "To capture edges in all directions, we compute filter in x and y then using **Steerable filters** to combine them at any angle with sin and cos weights.\n",
    "\n",
    "Images are discrete (pixels) but Gaussian is a continuous function, hence we do **filter approximation** using **Bionomial filters** like **Gaussian** and **Sobel Filter** to approximate derivatives of Gaussian.\n",
    "\n",
    "<img src=\"../../Files/fifth-semester/cv/6.png\" alt=\"Derivative of Gaussian Approximations\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9183cc3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- **First derivative filters** → detect edges\n",
    "- **Second derivative filters** → detect lines and ridges (changes)\n",
    "\n",
    "#### Laplacian filter\n",
    "\n",
    "Also detects edges using second derivatives in both x and y directions but Very sensitive to noise\n",
    "\n",
    "- Will subtract blurred image from original image to get edges\n",
    "\n",
    "Hence we apply **Laplacian of Gaussian (LoG)**: Smooth with Gaussian then apply Laplacian filter or combine both into one filter by convolving Gaussian + Laplacian filter.\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../../Files/fifth-semester/cv/7.png\" alt=\"Laplacian of Gaussian Approximations\" width=\"400\"/>\n",
    "\n",
    "#### Hybrid Images\n",
    "\n",
    "- Combine low frequencies of one image with high frequencies of another image to create a hybrid image that changes based on viewing distance.\n",
    "- It's an application of laplacian and gaussian filters.\n",
    "\n",
    "<img src=\"../../Files/fifth-semester/cv/8.png\" alt=\"Hybrid Images\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658ac01",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "\n",
    "####  Non-linear Filters\n",
    "\n",
    "A filter is non-linear if:\n",
    "- The output is not a weighted sum of pixels\n",
    "- You cannot write it as convolution\n",
    "- Superposition does not hold\n",
    "\n",
    "Salt-and-pepper noise, Random B/W pixles -> Median filter better than Gaussian filter\n",
    "\n",
    "Examples and solutions:\n",
    "- Median filter\n",
    "    - Edges preserved better than Gaussian\n",
    "    - Window size effect:\n",
    "        - Small window → light denoising\n",
    "        - Large window → strong denoising\n",
    "        - Too large → loss of detail\n",
    "- Bilateral filter (edge-preserving smoothing):\n",
    "    - Smooths flat regions, Preserves edges and Removes noise without strong blur with two weights:\n",
    "        - Spatial Gaussian : Near pixels matter more\n",
    "        - Range Gaussian : Similar intensity pixels matter more\n",
    "    - Issue: Applying bilateral filter multiple times makes Flattens regions more and more + Edges become stronger relative to regions (Cartoonish effect)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8412f929",
   "metadata": {},
   "source": [
    "#### Image patches as filters (image matches)\n",
    "\n",
    "- **Raw correlation**: Slide the patch over image like kernel filter with dot product\n",
    "    - Issue: Sensitive to brightness → bright areas give high response\n",
    "- **Zero-mean correlation**: Subtract mean from patch and image region before dot product\n",
    "    - Solves brightness issue\n",
    "    - Issue: Sensitive to contrast → high contrast areas give high response\n",
    "- **Normalized cross-correlation** (NCC): Divide by norm of patch and image region after zero-mean\n",
    "    - Solves contrast issue\n",
    "    - Invariant to brightness and contrast changes\n",
    "    - Peaks = true matches\n",
    "\n",
    "Main Issues:\n",
    "- Works only for same scale and appearance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979a229",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pattern matching\n",
    "- With filters (cross-correlation / convolution) we can do pattern matching but the main issues are:\n",
    "    - Works only for same scale and appearance\n",
    "    - Sensitive to rotation and viewpoint changes\n",
    "    - So we need translation and scale invariant features\n",
    "\n",
    "#### Image Pyramids\n",
    "\n",
    "Create multiple scaled versions of the image (downsampling) and Perform matching at each scale\n",
    "\n",
    "Build downsampled of images each smaller than previous = multi-scale pyramid\n",
    "\n",
    "#### Subsampling and aliasing\n",
    "\n",
    "When downsampling, high-frequency details can cause aliasing artifacts means when downsampling\n",
    "- Details dissapear\n",
    "- New false patterns appear\n",
    "\n",
    "Solution: Remove high-frequency details by blurring (Gaussian pyramid) before\n",
    "\n",
    "#### Laplacian Pyramids\n",
    "\n",
    "We have Gaussian pyramid but we can also create Laplacian pyramid by subtracting each level of Gaussian pyramid from the next lower level (upsampled). Basically:\n",
    "- Gaussian pyramid:\n",
    "    - Smooth image\n",
    "    - Low-frequency content\n",
    "- Laplacian pyramid:\n",
    "    - Difference image\n",
    "    - Edges + details at that scale\n",
    "\n",
    "Applications:\n",
    "- Image compression: Store Laplacian pyramid levels + smallest Gaussian level\n",
    "- Texture synthesis: Manipulate Laplacian levels to change texture details\n",
    "- Noise reduction: Threshold Laplacian levels to remove noise\n",
    "- Computing image features/keypoints\n",
    "- Connection to NN\n",
    "\n",
    "It's reversible and we can upsample and add levels to reconstruct original image.\n",
    "\n",
    "#### Upsampling\n",
    "\n",
    "We add zeros between pixels and then apply Gaussian filter with compatible small kernel to interpolate missing pixels.\n",
    "\n",
    "#### Image Blending with the Laplacian Pyramid\n",
    "$ I = ml^A + (1 - m)l^B $\n",
    "\n",
    "Different scales blended with different masks to get smooth transition between two images.\n",
    "\n",
    "Gaussian and Laplacian pyramids are linear transformations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93c87a",
   "metadata": {},
   "source": [
    "### Image Statistics\n",
    "\n",
    "We use **Intensity histograms** to analyze image statistics. which for rel images looks to noise for fake images or noisy images looks smoother.\n",
    "\n",
    "The distribution of filter responses (especially gradients) is very consistent across natural images.\n",
    "\n",
    "Blurry images (like motion blur) have different gradient statistics than sharp images\n",
    "\n",
    "<img src=\"../../Files/fifth-semester/cv/9.png\" alt=\"Image Statistics\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8cd51",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Texture Analysis\n",
    "\n",
    "Humans are sensitive to simple statistics (not exact pixels)\n",
    "\n",
    "Julesz conjecture (historical idea):\n",
    "\n",
    "> Textures look the same if their 1st and 2nd order statistics match\n",
    "(later shown to be incomplete, but useful)\n",
    "\n",
    "**Texture statistics**:\n",
    "- 1st order: Probability of pixel values (histogram)\n",
    "- 2nd order: Probability of pairs of pixel values at distance\n",
    "\n",
    "We apply **filter bank** (edges, orientations, scales) to image and compute statistics of filter responses (mean, variance, histogram) to capture texture information.\n",
    "\n",
    "**Steerable pyramid** is a multi-scale filter bank used to analyze, compare and synthesize textures.\n",
    "\n",
    "**Encoder** decomposes the image using a steerable pyramid (not Gaussian/Laplacian), then computes statistics.\n",
    "\n",
    "**Decoder** synthesizes texture from statistics by starting from noise and iteratively adjusting to match statistics.\n",
    "\n",
    "**Texture Synthesis (Parametric)**\n",
    "- Start with a noise\n",
    "- Match pixel histogram\n",
    "- Match filter response histograms\n",
    "- Reconstruct and repeat\n",
    "\n",
    "**Non-parametric texture synthesis**:\n",
    "- Copy pixels from the input image based on similar neighborhoods\n",
    "    - Grow image pixel by pixel\n",
    "    - For each pixel, find similar neighborhoods in input\n",
    "    - Randomly sample from them\n",
    "\n",
    "Two ways to synthesize texture:\n",
    "- Parametric: match filter statistics (pyramids).\n",
    "- Non-parametric: copy pixels using similar neighborhoods."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
