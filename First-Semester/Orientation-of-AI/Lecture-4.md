# AI singularity
Development is overestimated in the short-term, but underestimated in the long term. It takes a long time of quiet accumulation before we can get a short burst of loud technological advancement shock.  
The singularity is a point which you can not look beyond. It can be an intelligence explosion that most find difficult to imagine.

According to I.J. Good, the first ultra-intelligent machine we develop will be the last machine humanity designs as every other machine will be designed by that first ultra-intelligent one.  
## Value alignment
Beware what you wish for, the idea that we keep AI under control uses the assumption that we can specify exactly what we wish for without any unexpected side effects.

### Examples
Medias' golden touch example. Specification game example, a game that wants to achieve a certain goal but the AI attempts to reach the goal through an unexpected method. The MIT Moral Machine Trolley problem, collecting people's input to train the machine on morals, did not turn out well.

## Intent and ethics
AI has no intent, it depends on the person who created and used the AI whether it is good or bad. (Similar to dynamite)  
There are multiple branches in philosophy, ethics is a philosophy branch that relates to how we value things. (Similar to aesthetics)  
When people think of ethics, they typically think whether or not something is applicably moral, but ethics also involves thinking about different ways of thought on what is good and what is bad as well as how we decide rules and the ethics of following them (or not) using principles.
